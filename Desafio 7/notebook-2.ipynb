{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Insira seu project token aqui"}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": "# MARATONA BEHIND THE CODE 2020\n\n## DESAFIO 7 - TNT"}, {"cell_type": "markdown", "metadata": {}, "source": "<hr>"}, {"cell_type": "markdown", "metadata": {}, "source": "## Installing Libs"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "!pip install scikit-learn --upgrade"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "!pip install xgboost --upgrade"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "!pip install imblearn --upgrade"}, {"cell_type": "markdown", "metadata": {}, "source": "<hr>"}, {"cell_type": "markdown", "metadata": {}, "source": "## Download dos conjuntos de dados em formato .csv"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "import pandas as pd"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Insira aqui o pandasDataFrame."}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "df_training_dataset = df_data_1\ndf_training_dataset.tail()"}, {"cell_type": "markdown", "metadata": {}, "source": "Sobre o arquivo \"training_dataset.csv\", temos algumas informa\u00e7\u00f5es gerais sobre os usu\u00e1rios do app do BanCoppel:\n\n**Tempo**\n\n**Esta\u00e7\u00e3o**\n\n**LAT**\n\n**LONG**\n\n**Movimenta\u00e7\u00e3o**\n\n**Original_473**\n\n**Original_269**\n\n**Zero**\n\n**Ma\u00e7\u00e3-Verde**\n\n**Tangerina**\n\n**Citrus**\n\n**A\u00e7a\u00ed-Guaran\u00e1**\n\n**P\u00eassego**\n\n**TARGET**"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "df_training_dataset.info()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "df_training_dataset.nunique()"}, {"cell_type": "markdown", "metadata": {}, "source": "<hr>\n\n## Detalhamento do desafio: classifica\u00e7\u00e3o bin\u00e1ria\n\nEste \u00e9 um desafio cujo objetivo de neg\u00f3cio \u00e9 a segmenta\u00e7\u00e3o dos usu\u00e1rios de aplicativo de um banco. Para tal, podemos utilizar duas abordagens: aprendizado de m\u00e1quina supervisionado (classifica\u00e7\u00e3o) ou n\u00e3o-supervisionado (clustering). Neste desafio ser\u00e1 aplicada a classifica\u00e7\u00e3o, pois \u00e9 dispon\u00edvel um dataset j\u00e1 com \"labels\", ou em outras palavras, j\u00e1 com exemplos de dados juntamente com a vari\u00e1vel alvo.\n\nNa biblioteca scikit-learn temos diversos algoritmos para classifica\u00e7\u00e3o. O participante \u00e9 livre para utilizar o framework que desejar para completar esse desafio.\n\nNeste notebook ser\u00e1 mostrado um exeplo de uso do algoritmo \"Decision Tree\" para classificar parte dos estudantes em seis diferentes perf\u00eds."}, {"cell_type": "markdown", "metadata": {}, "source": "# Aten\u00e7\u00e3o!\n\nA coluna-alvo neste desafio \u00e9 a coluna ``TARGET``"}, {"cell_type": "markdown", "metadata": {}, "source": "<hr>"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "markdown", "metadata": {}, "source": "## Pre-processando o dataset antes do treinamento"}, {"cell_type": "markdown", "metadata": {}, "source": "### Processando valores NaN com o SimpleImputer do sklearn\n\nPara os valores NaN, usaremos a substitui\u00e7\u00e3o pela constante 0 como **exemplo**.\n\nVoc\u00ea pode escolher a estrat\u00e9gia que achar melhor para tratar os valores nulos :)\n\nDocs: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html?highlight=simpleimputer#sklearn.impute.SimpleImputer"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "from sklearn.impute import SimpleImputer\nimport numpy as np\n\n\nimpute_zeros = SimpleImputer(\n    missing_values=np.nan,\n    strategy='constant',\n    fill_value=0,\n    verbose=0,\n    copy=True\n)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Exibindo os dados ausentes do conjunto de dados antes da primeira transforma\u00e7\u00e3o (df)\nprint(\"Valores nulos no df_training_dataset antes da transforma\u00e7\u00e3o SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset.isnull().sum(axis = 0)))\n\n# Aplicando a transforma\u00e7\u00e3o ``SimpleImputer`` no conjunto de dados base\nimpute_zeros.fit(X=df_training_dataset)\n\n# Reconstruindo um Pandas DataFrame com os resultados\ndf_training_dataset_imputed = pd.DataFrame.from_records(\n    data=impute_zeros.transform(\n        X=df_training_dataset\n    ),\n    columns=df_training_dataset.columns\n)\n\n# Exibindo os dados ausentes do conjunto de dados ap\u00f3s a primeira transforma\u00e7\u00e3o (df)\nprint(\"Valores nulos no df_training_dataset ap\u00f3s a transforma\u00e7\u00e3o SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset_imputed.isnull().sum(axis = 0)))"}, {"cell_type": "markdown", "metadata": {}, "source": "### Eliminando colunas indesejadas\n\nVamos **demonstrar** abaixo como usar o m\u00e9todo **DataFrame.drop()**.\n\nDocs: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "df_training_dataset_imputed.tail()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "df_training_dataset_rmcolumns = df_training_dataset_imputed.drop(columns=['Tempo', 'Esta\u00e7\u00e3o', 'LAT', 'LONG', 'Movimenta\u00e7\u00e3o'], inplace=False)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "df_training_dataset_rmcolumns.tail()"}, {"cell_type": "markdown", "metadata": {}, "source": "# Aten\u00e7\u00e3o!\n\nAs colunas removidas acima s\u00e3o apenas para fim de exemplo, voc\u00ea pode usar as colunas que quiser e inclusive criar novas colunas com dados que achar importantes!\n"}, {"cell_type": "markdown", "metadata": {}, "source": "### Tratamento de de vari\u00e1veis categ\u00f3ricas\n\nComo mencionado antes, os computadores n\u00e3o s\u00e3o bons com vari\u00e1veis \"categ\u00f3ricas\" (ou strings).\n\nDado uma coluna com vari\u00e1vel categ\u00f3rica, o que podemos realizar \u00e9 a codifica\u00e7\u00e3o dessa coluna em m\u00faltiplas colunas contendo vari\u00e1veis bin\u00e1rias. Esse processo \u00e9 chamado de \"one-hot-encoding\" ou \"dummy encoding\". Se voc\u00ea n\u00e3o \u00e9 familiarizado com esses termos, voc\u00ea pode pesquisar mais sobre isso na internet :)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Tratando vari\u00e1veis categ\u00f3ricas com o m\u00e9todo Pandas ``get_dummies()''\n# df_training = pd.get_dummies(df_training_dataset_rmcolumns, columns=['Vari\u00e1vel a ser aplicado m\u00e9todo getDumies()'])\ndf_training = df_training_dataset_rmcolumns\ndf_training.tail()"}, {"cell_type": "markdown", "metadata": {}, "source": "# Aten\u00e7\u00e3o!\n\nA coluna **TARGET** deve ser mantida como uma string. Voc\u00ea n\u00e3o precisa processar/codificar a vari\u00e1vel-alvo."}, {"cell_type": "markdown", "metadata": {}, "source": "<hr>"}, {"cell_type": "markdown", "metadata": {}, "source": "## Treinando um classificador com base em uma \u00e1rvore de decis\u00e3o"}, {"cell_type": "markdown", "metadata": {}, "source": "### Selecionando FEATURES e definindo a vari\u00e1vel TARGET"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "df_training.columns"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "features = df_training[\n    [\n        'Original_473', 'Original_269', 'Zero', 'Ma\u00e7\u00e3-Verde', 'Tangerina',\n       'Citrus', 'A\u00e7a\u00ed-Guaran\u00e1', 'P\u00eassego'\n    ]\n]\ntarget = df_training['TARGET']  ## N\u00c3O TROQUE O NOME DA VARI\u00c1VEL TARGET."}, {"cell_type": "markdown", "metadata": {}, "source": "### Dividindo nosso conjunto de dados em conjuntos de treinamento e teste"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "from sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=133)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Treinando uma \u00e1rvore de decis\u00e3o"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# M\u00e9todo para criar um \u00e1rvore de decis\u00e3o\nfrom sklearn.tree import DecisionTreeClassifier\n\n\ndtc = DecisionTreeClassifier(max_depth=15).fit(X_train, y_train)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Fazendo previs\u00f5es na amostra de teste"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "y_pred = dtc.predict(X_test)\nprint(y_pred)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Analisando a qualidade do modelo atrav\u00e9s da matriz de confus\u00e3o"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "import matplotlib.pyplot as plt\nimport numpy as np\nimport itertools\n\n\ndef plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "from sklearn.metrics import confusion_matrix\n\n\nplot_confusion_matrix(confusion_matrix(y_test, y_pred), ['NORMAL', 'REABASTECER'])"}, {"cell_type": "markdown", "metadata": {}, "source": "<hr>"}, {"cell_type": "markdown", "metadata": {}, "source": "## Scoring dos dados necess\u00e1rios para entregar a solu\u00e7\u00e3o"}, {"cell_type": "markdown", "metadata": {}, "source": "Como entrega da sua solu\u00e7\u00e3o, esperamos os resultados classificados no seguinte dataset chamado \"to_be_scored.csv\":"}, {"cell_type": "markdown", "metadata": {}, "source": "### Download da \"folha de respostas\""}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false}, "outputs": [], "source": "!wget --no-check-certificate --content-disposition https://gitlab.com/JoaoPedroPP/datasets/-/raw/master/ntn/to_be_scored.csv\ndf_to_be_scored = pd.read_csv(r'to_be_scored.csv')\ndf_to_be_scored.tail()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "df_to_be_scored = pd.read_csv('to_be_scored.csv')\ndf_to_be_scored.tail()"}, {"cell_type": "markdown", "metadata": {}, "source": "# Aten\u00e7\u00e3o!\n\nO dataframe ``to_be_scored`` \u00e9 a sua \"folha de respostas\". Note que a coluna \"TARGET\" n\u00e3o existe nessa amostra, que n\u00e3o pode ser ent\u00e3o utilizada para treino de modelos de aprendizado supervisionado."}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": "df_to_be_scored.info()"}, {"cell_type": "markdown", "metadata": {}, "source": "<hr>\n\n# Aten\u00e7\u00e3o!\n\n# Para poder aplicar seu modelo e classificar a folha de respostas, voc\u00ea precisa primeiro aplicar as mesmas transforma\u00e7\u00f5es com colunas que voc\u00ea aplicou no dataset de treino.\n\n# N\u00e3o remova ou adicione linhas na folha de respostas. \n\n# N\u00e3o altere a ordem das linhas na folha de respostas.\n\n# Ao final, as 1000 entradas devem estar classificadas, com os valores previstos em uma coluna chamada \"target\"\n\n<hr>"}, {"cell_type": "markdown", "metadata": {}, "source": "Na c\u00e9lula abaixo, repetimos rapidamente os mesmos passos de pr\u00e9-processamento usados no exemplo dado com \u00e1rvore de decis\u00e3o"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# 1 - Removendo linhas com valores NaN\ndf_to_be_scored_1 = df_to_be_scored.dropna(axis='index', how='any', subset=['Tempo', 'Esta\u00e7\u00e3o', 'LAT', 'LONG', 'Movimenta\u00e7\u00e3o', 'Original_473', 'Original_269', 'Zero', 'Ma\u00e7\u00e3-Verde', 'Tangerina', 'Citrus', 'A\u00e7a\u00ed-Guaran\u00e1', 'P\u00eassego'])\n\n# 2 - Inputando zeros nos valores faltantes\nimpute_zeros.fit(X=df_to_be_scored_1)\ndf_to_be_scored_2 = pd.DataFrame.from_records(\n    data=impute_zeros.transform(\n        X=df_to_be_scored_1\n    ),\n    columns=df_to_be_scored_1.columns\n)\n\n# 3 - Remo\u00e7\u00e3o de colunas\ndf_to_be_scored_3 = df_to_be_scored_2.drop(columns=['Tempo', 'Esta\u00e7\u00e3o', 'LAT', 'LONG', 'Movimenta\u00e7\u00e3o'], inplace=False)\n\n# 4 - Encoding com \"dummy variables\" (se necess\u00e1rio)\n# df_to_be_scored_4 = pd.get_dummies(df_to_be_scored_3, columns=['V\u00e1riavel com dummy'])\ndf_to_be_scored_4 = df_to_be_scored_3\n\ndf_to_be_scored_4.tail()"}, {"cell_type": "markdown", "metadata": {}, "source": "<hr>\n\nPode ser verificado abaixo que as colunas da folha de resposta agora s\u00e3o id\u00eanticas \u00e0s que foram usadas para treinar o modelo:"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "df_training[\n    [\n        'Original_473', 'Original_269', 'Zero', 'Ma\u00e7\u00e3-Verde', 'Tangerina',\n       'Citrus', 'A\u00e7a\u00ed-Guaran\u00e1', 'P\u00eassego'\n    ]\n].columns"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "df_to_be_scored_4.columns"}, {"cell_type": "markdown", "metadata": {}, "source": "# Aten\u00e7\u00e3o\n\nPara todas colunas que n\u00e3o existirem no \"df_to_be_scored\", voc\u00ea pode usar a t\u00e9cnica abaixo para adicion\u00e1-las:"}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false}, "outputs": [], "source": "y_pred = dtc.predict(df_to_be_scored_4)\ndf_to_be_scored_4['TARGET'] = y_pred\ndf_to_be_scored_4.tail()"}, {"cell_type": "markdown", "metadata": {}, "source": "### Salvando a folha de respostas como um arquivo .csv para ser submetido"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "project.save_data(file_name=\"results.csv\", data=df_to_be_scored_4.to_csv(index=False))"}, {"cell_type": "markdown", "metadata": {}, "source": "# Aten\u00e7\u00e3o\n\n# A execu\u00e7\u00e3o da c\u00e9lula acima ir\u00e1 criar um novo \"data asset\" no seu projeto no Watson Studio. Voc\u00ea precisar\u00e1 realizar o download deste arquivo juntamente com este notebook e criar um arquivo zip com os arquivos **results.csv** e **notebook.ipynb** para submiss\u00e3o. (os arquivos devem estar nomeados desta forma)"}, {"cell_type": "markdown", "metadata": {}, "source": "<hr>\n\n## Parab\u00e9ns!\n\nSe voc\u00ea j\u00e1 est\u00e1 satisfeito com a sua solu\u00e7\u00e3o, v\u00e1 at\u00e9 a p\u00e1gina abaixo e envie os arquivos necess\u00e1rios para submiss\u00e3o.\n\n# https://tnt.maratona.dev\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3.6", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.9"}}, "nbformat": 4, "nbformat_minor": 1}